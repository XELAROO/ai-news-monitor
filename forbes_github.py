import os
import json
import hashlib
import time
from datetime import datetime

try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.common.by import By
    from webdriver_manager.chrome import ChromeDriverManager
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–æ—Ä–µ–Ω—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ src/)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
LAST_NEWS_FILE = os.path.join(BASE_DIR, 'last_news.json')
RESULTS_DIR = os.path.join(BASE_DIR, 'results')
NEWS_COUNT_FILE = os.path.join(BASE_DIR, 'news_count.txt')

def ensure_dirs():
    """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
    os.makedirs(RESULTS_DIR, exist_ok=True)
    print(f"üìÅ Results dir: {RESULTS_DIR}")
    print(f"üìÅ Results dir exists: {os.path.exists(RESULTS_DIR)}")
    print(f"üìÅ Results dir absolute path: {os.path.abspath(RESULTS_DIR)}")

def generate_fingerprint(title, url):
    return hashlib.md5(f"{title}|{url}".encode()).hexdigest()

def load_last_news():
    if os.path.exists(LAST_NEWS_FILE):
        try:
            with open(LAST_NEWS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ùå Error loading last_news: {e}")
            return None
    return None

def save_last_news(news_item):
    news_item['fingerprint'] = generate_fingerprint(news_item['title'], news_item['link'])
    news_item['last_updated'] = datetime.now().isoformat()
    with open(LAST_NEWS_FILE, 'w', encoding='utf-8') as f:
        json.dump(news_item, f, ensure_ascii=False, indent=2)
    print(f"üíæ Last news saved to: {LAST_NEWS_FILE}")

def is_same_news(news1, news2):
    if not news1 or not news2:
        return False
    if news1.get('fingerprint') and news2.get('fingerprint'):
        if news1['fingerprint'] == news2['fingerprint']:
            return True
    if news1['link'] == news2['link']:
        return True
    title1 = news1['title'].lower().strip()
    title2 = news2['title'].lower().strip()
    if title1 == title2:
        return True
    words1 = set(title1.split())
    words2 = set(title2.split())
    if words1 and words2:
        similarity = len(words1.intersection(words2)) / max(len(words1), len(words2))
        return similarity > 0.7
    return False

def setup_selenium():
    options = Options()
    options.add_argument('--headless=new')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36')
    
    try:
        service = Service(ChromeDriverManager().install())
        return webdriver.Chrome(service=service, options=options)
    except Exception as e:
        print(f"‚ùå Chrome error: {e}")
        try:
            options.binary_location = '/usr/bin/google-chrome'
            return webdriver.Chrome(options=options)
        except:
            return None

def parse_forbes_ai():
    print("üöÄ Starting parser with precise XPath...")
    
    if not SELENIUM_AVAILABLE:
        return []
    
    last_news = load_last_news()
    if last_news:
        print(f"üìñ Last known: {last_news['title'][:60]}...")
    else:
        print("üìñ No previous news")
    
    driver = None
    try:
        driver = setup_selenium()
        if not driver:
            return []
        
        print("üìÑ Loading Forbes AI...")
        driver.get("https://www.forbes.com/ai/")
        time.sleep(8)
        
        articles = []
        all_articles = []  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ - –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
        
        print("üîç Finding news using precise XPath...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ "More From AI" —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        try:
            more_from_ai = driver.find_element(By.XPATH, '//*[@id="row-2"]/div/div/div/div[1]/div[1]/h2')
            print("‚úÖ Found 'More From AI' section")
        except:
            print("‚ùå 'More From AI' section not found")
            return []
        
        # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–µ—Ä–µ–º –í–°–ï —Å—Ç–∞—Ç—å–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        news_index = 1
        while True:
            try:
                # XPath –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ –Ω–æ–≤–æ—Å—Ç–∏
                time_xpath = f'//*[@id="row-2"]/div/div/div/div[1]/div[2]/div[{news_index}]/div/div/div[2]/div[1]/time'
                time_elem = driver.find_element(By.XPATH, time_xpath)
                date_text = time_elem.text.strip()
                
                # XPath –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏
                title_xpath = f'//*[@id="row-2"]/div/div/div/div[1]/div[2]/div[{news_index}]/div/div/div[2]/h3'
                title_elem = driver.find_element(By.XPATH, title_xpath)
                title_link = title_elem.find_element(By.TAG_NAME, "a")
                title = title_link.text.strip()
                href = title_link.get_attribute('href')
                
                if title and href and len(title) > 10:
                    current_article = {
                        'date': date_text,
                        'title': title,
                        'link': href,
                        'fingerprint': generate_fingerprint(title, href)
                    }
                    
                    all_articles.append(current_article)
                    print(f"üì∞ Found article {news_index}: {title[:50]}...")
                    
                news_index += 1
                
            except Exception as e:
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —ç–ª–µ–º–µ–Ω—Ç - –∑–Ω–∞—á–∏—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å
                print(f"üì≠ No more news found (index {news_index}), total found: {len(all_articles)}")
                break
        
        # –¢–µ–ø–µ—Ä—å –æ–ø—Ä–µ–¥–µ–ª–∏–º, –∫–∞–∫–∏–µ —Å—Ç–∞—Ç—å–∏ —è–≤–ª—è—é—Ç—Å—è –Ω–æ–≤—ã–º–∏
        if last_news:
            print(f"\nüîç Looking for last known news: {last_news['title'][:50]}...")
            last_news_index = -1
            
            # –ù–∞–π–¥–µ–º –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –∏–∑–≤–µ—Å—Ç–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏
            for i, article in enumerate(all_articles):
                if is_same_news(article, last_news):
                    last_news_index = i
                    print(f"‚úÖ Found last known news at position {i+1}")
                    break
            
            if last_news_index >= 0:
                # –í—Å–µ —Å—Ç–∞—Ç—å–∏ –î–û –ø–æ—Å–ª–µ–¥–Ω–µ–π –∏–∑–≤–µ—Å—Ç–Ω–æ–π - —ç—Ç–æ –Ω–æ–≤—ã–µ —Å—Ç–∞—Ç—å–∏
                articles = all_articles[:last_news_index]
                print(f"üéØ New articles found: {len(articles)} (positions 1-{last_news_index})")
            else:
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è –∏–∑–≤–µ—Å—Ç–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –±–µ—Ä–µ–º –≤—Å–µ —Å—Ç–∞—Ç—å–∏
                articles = all_articles
                print(f"‚ö†Ô∏è Last known news not found, taking all {len(articles)} articles")
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π, –±–µ—Ä–µ–º –≤—Å–µ
            articles = all_articles
            print(f"üìù No previous news, taking all {len(articles)} articles")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∞–º—É—é —Å–≤–µ–∂—É—é –Ω–æ–≤–æ—Å—Ç—å –∫–∞–∫ –º–∞—Ä–∫–µ—Ä –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
        if all_articles:
            save_last_news(all_articles[0])
            print(f"üíæ New last news saved: {all_articles[0]['title'][:60]}...")
        
        return articles
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return []
    finally:
        if driver:
            driver.quit()

def force_file_sync(filename):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–∞ —Å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π"""
    try:
        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª
        with open(filename, 'a') as f:
            os.fsync(f.fileno())
        print(f"üîÑ File synced: {filename}")
    except Exception as e:
        print(f"‚ö†Ô∏è File sync warning: {e}")

def save_results(articles):
    ensure_dirs()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = os.path.join(RESULTS_DIR, f"github_{timestamp}.txt")
    
    print(f"üìù Creating file: {filename}")
    print(f"üìù Absolute file path: {os.path.abspath(filename)}")
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("FORBES AI - GITHUB PARSER\n")
            f.write("=" * 50 + "\n")
            f.write(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"New articles: {len(articles)}\n\n")
            
            for i, article in enumerate(articles, 1):
                f.write(f"{i}. DATE: {article['date']}\n")
                f.write(f"   TITLE: {article['title']}\n")
                f.write(f"   LINK: {article['link']}\n")
                f.write("-" * 50 + "\n")
        
        # üî• –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è
        force_file_sync(filename)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–ª—Å—è
        if os.path.exists(filename):
            file_size = os.path.getsize(filename)
            print(f"‚úÖ File successfully created: {filename}")
            print(f"‚úÖ File size: {file_size} bytes")
            print(f"‚úÖ File exists: {os.path.exists(filename)}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - —á–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            with open(filename, 'r', encoding='utf-8') as f:
                content = f.read()
                print(f"‚úÖ File content verified, length: {len(content)} chars")
        else:
            print(f"‚ùå File was not created: {filename}")
            return None
            
    except Exception as e:
        print(f"‚ùå Error saving file: {e}")
        return None
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π
    try:
        with open(NEWS_COUNT_FILE, 'w', encoding='utf-8') as f:
            f.write(str(len(articles)))
        
        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º news_count.txt
        force_file_sync(NEWS_COUNT_FILE)
        
        print(f"üíæ News count saved to: {NEWS_COUNT_FILE}")
        print(f"üíæ News count value: {len(articles)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        with open(NEWS_COUNT_FILE, 'r', encoding='utf-8') as f:
            saved_count = f.read().strip()
            print(f"üíæ News count verified: {saved_count}")
            
    except Exception as e:
        print(f"‚ùå Error saving news count: {e}")
    
    return filename

def check_results_directory():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –≤—ã–≤–æ–¥–∏—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏ results"""
    print(f"\nüîç CHECKING RESULTS DIRECTORY:")
    print(f"üìÅ Path: {RESULTS_DIR}")
    print(f"üìÅ Exists: {os.path.exists(RESULTS_DIR)}")
    
    if os.path.exists(RESULTS_DIR):
        files = os.listdir(RESULTS_DIR)
        print(f"üìÅ Number of files: {len(files)}")
        for file in sorted(files, reverse=True):  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
            file_path = os.path.join(RESULTS_DIR, file)
            file_size = os.path.getsize(file_path)
            print(f"   üìÑ {file} ({file_size} bytes)")
    else:
        print("‚ùå Results directory does not exist!")

def main():
    print("=" * 60)
    print("üéØ FORBES AI - GITHUB PARSER")
    print("=" * 60)
    
    articles = parse_forbes_ai()
    
    if articles:
        print(f"\n‚úÖ SUCCESS! Found: {len(articles)} new articles")
        
        print("üìã New articles list:")
        for i, article in enumerate(articles, 1):
            print(f"   {i}. {article['title'][:60]}...")
        
        filename = save_results(articles)
        
        if filename and os.path.exists(filename):
            print(f"üíæ All files saved successfully")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏ results
            check_results_directory()
            
        else:
            print(f"‚ùå File was not created successfully")
            
    else:
        print("üì≠ No new news found")
        # –í—Å–µ —Ä–∞–≤–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º 0 –≤ news_count.txt
        try:
            with open(NEWS_COUNT_FILE, 'w', encoding='utf-8') as f:
                f.write("0")
            
            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º
            force_file_sync(NEWS_COUNT_FILE)
            
            print(f"üíæ News count saved: 0")
        except Exception as e:
            print(f"‚ùå Error saving news count: {e}")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    print(f"\nüéØ FINAL DIRECTORY CHECK:")
    check_results_directory()

if __name__ == "__main__":
    main()
