import os
import aiohttp
import asyncio
import json
import glob
import logging
import time
from datetime import datetime, timezone, timedelta

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
YANDEX_API_KEY = os.getenv('YANDEX_API_KEY')
YANDEX_FOLDER_ID = os.getenv('YANDEX_FOLDER_ID')
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHANNEL_ID = os.getenv('TELEGRAM_CHANNEL_ID')

class ExistingFilesNewsManager:
    def __init__(self, files_pattern="results/github_*.txt", sent_file="sent_news.json"):
        self.files_pattern = files_pattern
        self.sent_file = sent_file
        self.sent_news = self.load_sent_news()
    
    def load_sent_news(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏"""
        if os.path.exists(self.sent_file):
            try:
                with open(self.sent_file, 'r', encoding='utf-8') as f:
                    return set(json.load(f))
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ sent_news.json: {e}")
                return set()
        return set()
    
    def save_sent_news(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏"""
        try:
            with open(self.sent_file, 'w', encoding='utf-8') as f:
                json.dump(list(self.sent_news), f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è sent_news.json: {e}")
    
    def parse_news_file(self, filepath):
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª –≤ –ª—é–±–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (Forbes –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ–º)"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ï—Å–ª–∏ —ç—Ç–æ —Ñ–æ—Ä–º–∞—Ç Forbes Parser
            if 'FORBES AI - GITHUB PARSER' in content:
                return self.parse_forbes_format(content)
            else:
                # –ü—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç (–æ–¥–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å –Ω–∞ —Å—Ç—Ä–æ–∫—É)
                return [line.strip() for line in content.split('\n') if line.strip() and '|' in line]
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {filepath}: {e}")
            return []
    
    def parse_forbes_format(self, content):
        """–ü–∞—Ä—Å–∏—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç Forbes –∏ –æ—á–∏—â–∞–µ—Ç URL"""
        news_lines = []
        blocks = content.split('--------------------------------------------------')
        
        for block in blocks:
            if 'TITLE:' in block and 'LINK:' in block:
                lines = block.strip().split('\n')
                title = None
                link = None
                
                for line in lines:
                    line = line.strip()
                    if line.startswith('TITLE:'):
                        title = line.replace('TITLE:', '').strip()
                    elif line.startswith('LINK:'):
                        link = line.replace('LINK:', '').strip()
                        # –û—á–∏—â–∞–µ–º URL –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ?ss=ai
                        link = self.clean_forbes_url(link)
                
                if title and link:
                    news_lines.append(f"{title} | {link}")
        
        logger.info(f"üì∞ –†–∞—Å–ø–∞—Ä—à–µ–Ω–æ {len(news_lines)} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ Forbes —Ñ–æ—Ä–º–∞—Ç–∞")
        return news_lines

    def clean_forbes_url(self, url):
        """–û—á–∏—â–∞–µ—Ç Forbes URL –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ?ss=ai –∏ –¥—Ä—É–≥–∏—Ö —Ç—Ä–µ–∫–µ—Ä–æ–≤"""
        try:
            # –£–¥–∞–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ?ss=ai –∏ –¥—Ä—É–≥–∏–µ UTM-–º–µ—Ç–∫–∏
            if '?' in url:
                base_url = url.split('?')[0]
                logger.info(f"üîó –û—á–∏—â–µ–Ω URL: {url} -> {base_url}")
                return base_url
            return url
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ URL {url}: {e}")
            return url
    
    def get_oldest_unsent_news(self):
        """–ù–∞—Ö–æ–¥–∏—Ç —Å–∞–º—É—é –°–í–ï–ñ–£–Æ –Ω–µ–ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤"""
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
        news_files = glob.glob(self.files_pattern)
        if not news_files:
            logger.info("üì≠ –§–∞–π–ª—ã —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return None
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (—Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π –ø–µ—Ä–≤—ã–π)
        news_files.sort(key=os.path.getctime)
        logger.info(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(news_files)}")
        
        for filepath in news_files:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –ø–∞—Ä—Å–µ—Ä –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–≥–æ —á—Ç–µ–Ω–∏—è
            news_lines = self.parse_news_file(filepath)
            
            logger.info(f"üìñ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ {os.path.basename(filepath)}: {len(news_lines)} –Ω–æ–≤–æ—Å—Ç–µ–π")
            
            # –ò—â–µ–º –Ω–µ–ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ –û–ë–†–ê–¢–ù–û–ú –ø–æ—Ä—è–¥–∫–µ (—Å–Ω–∞—á–∞–ª–∞ —Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ)
            for news_line in reversed(news_lines):
                # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–∏
                news_hash = hash(news_line)
                if news_hash not in self.sent_news:
                    logger.info(f"üéØ –ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å: {news_line[:50]}...")
                    return news_line, news_hash, filepath
                        
        logger.info("‚úÖ –í—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã")
        return None
    
    def mark_news_sent_and_cleanup(self, news_hash, news_line, filepath):
        """–ü–æ–º–µ—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç—å –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –∏ —á–∏—Å—Ç–∏—Ç —Ñ–∞–π–ª—ã"""
        # –ü–æ–º–µ—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç—å –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é
        self.sent_news.add(news_hash)
        self.save_sent_news()
        logger.info(f"‚úÖ –ù–æ–≤–æ—Å—Ç—å –ø–æ–º–µ—á–µ–Ω–∞ –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è: {news_line[:50]}...")
        
        # –£–¥–∞–ª—è–µ–º –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å –∏–∑ —Ñ–∞–π–ª–∞
        self.remove_news_from_file(filepath, news_line)
        
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        self.remove_empty_file(filepath)
    
    def remove_news_from_file(self, filepath, news_line_to_remove):
        """–£–¥–∞–ª—è–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —Å –ø–æ–º–æ—â—å—é –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞
            with open(filepath, 'r', encoding='utf-8') as f:
                original_content = f.read()
            
            # –ï—Å–ª–∏ —ç—Ç–æ Forbes —Ñ–æ—Ä–º–∞—Ç, —É–¥–∞–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –±–ª–æ–∫
            if 'FORBES AI - GITHUB PARSER' in original_content:
                updated_content = self.remove_forbes_news_block(original_content, news_line_to_remove)
            else:
                # –ü—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç - —É–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫—É
                lines = original_content.split('\n')
                updated_lines = [line for line in lines if line.strip() != news_line_to_remove]
                updated_content = '\n'.join(updated_lines)
            
            # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(updated_content)
                
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å –∏–∑ {os.path.basename(filepath)}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ —Ñ–∞–π–ª–∞: {e}")
    
    def remove_forbes_news_block(self, content, news_line_to_remove):
        """–£–¥–∞–ª—è–µ—Ç –±–ª–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ Forbes —Ñ–æ—Ä–º–∞—Ç–∞ (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        if '|' not in news_line_to_remove:
            return content
            
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ URL –∏–∑ news_line (—Ñ–æ—Ä–º–∞—Ç: "–∑–∞–≥–æ–ª–æ–≤–æ–∫ | url")
        title_to_remove, url_to_remove = [part.strip() for part in news_line_to_remove.split('|', 1)]
        
        blocks = content.split('--------------------------------------------------')
        updated_blocks = []
        removed_count = 0
        
        for block in blocks:
            # –ò—â–µ–º –±–ª–æ–∫, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —É–¥–∞–ª—è–µ–º–æ–π –Ω–æ–≤–æ—Å—Ç–∏
            if self.is_matching_forbes_block(block, title_to_remove, url_to_remove):
                logger.info(f"üóëÔ∏è –£–¥–∞–ª—è—é –±–ª–æ–∫ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º: {title_to_remove}")
                removed_count += 1
                continue
            updated_blocks.append(block)
        
        logger.info(f"üìä –£–¥–∞–ª–µ–Ω–æ –±–ª–æ–∫–æ–≤: {removed_count}")
        
        if removed_count == 0:
            logger.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω –±–ª–æ–∫ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: {title_to_remove}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ New articles
        result_content = '--------------------------------------------------'.join(updated_blocks)
        result_content = self.update_articles_count(result_content, removed_count)
        
        return result_content

    def is_matching_forbes_block(self, block, target_title, target_url):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –±–ª–æ–∫ Forbes –∏—Å–∫–æ–º–æ–π –Ω–æ–≤–æ—Å—Ç–∏"""
        if 'TITLE:' not in block or 'LINK:' not in block:
            return False
        
        lines = block.strip().split('\n')
        block_title = None
        block_url = None
        
        for line in lines:
            line = line.strip()
            if line.startswith('TITLE:'):
                block_title = line.replace('TITLE:', '').strip()
            elif line.startswith('LINK:'):
                block_url = line.replace('LINK:', '').strip()
                # –û—á–∏—â–∞–µ–º URL –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                block_url = self.clean_forbes_url(block_url)
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–µ URL (—ç—Ç–æ –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ —á–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏)
        if block_url and target_url:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            normalized_block_url = block_url.lower().rstrip('/')
            normalized_target_url = target_url.lower().rstrip('/')
            
            if normalized_block_url == normalized_target_url:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω matching –±–ª–æ–∫ –ø–æ URL: {block_url}")
                return True
        
        # –ï—Å–ª–∏ –ø–æ URL –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É (–º–µ–Ω–µ–µ –Ω–∞–¥–µ–∂–Ω–æ)
        if block_title and target_title:
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            normalized_block_title = ' '.join(block_title.lower().split())
            normalized_target_title = ' '.join(target_title.lower().split())
            
            if normalized_block_title == normalized_target_title:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω matching –±–ª–æ–∫ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É: {block_title}")
                return True
        
        return False

    def update_articles_count(self, content, removed_count=1):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—á–µ—Ç—á–∏–∫ New articles –≤ Forbes —Ñ–æ—Ä–º–∞—Ç–µ"""
        try:
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if line.strip().startswith('New articles:'):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                    current_count = int(line.split(':')[1].strip())
                    new_count = max(0, current_count - removed_count)
                    lines[i] = f"New articles: {new_count}"
                    logger.info(f"üìä –û–±–Ω–æ–≤–ª–µ–Ω —Å—á–µ—Ç—á–∏–∫: {current_count} -> {new_count}")
                    break
            
            return '\n'.join(lines)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞: {e}")
            return content
    
    def remove_empty_file(self, filepath):
        """–£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –µ—Å–ª–∏ –≤ –Ω–µ–º –Ω–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π"""
        try:
            if not os.path.exists(filepath):
                return
                
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ —Ñ–∞–π–ª–µ —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            if self.file_has_news(content):
                logger.info(f"üìÑ –í —Ñ–∞–π–ª–µ {os.path.basename(filepath)} –µ—â–µ –µ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–∏")
                return
            
            # –ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç - —É–¥–∞–ª—è–µ–º —Ñ–∞–π–ª
            os.remove(filepath)
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª {os.path.basename(filepath)}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–π–ª–∞ {filepath}: {e}")

    def file_has_news(self, content):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –≤ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º —Ñ–∞–π–ª–∞ –Ω–æ–≤–æ—Å—Ç–∏"""
        # –ï—Å–ª–∏ —ç—Ç–æ Forbes —Ñ–æ—Ä–º–∞—Ç
        if 'FORBES AI - GITHUB PARSER' in content:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –±–ª–æ–∫–∏ —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏ (—Å TITLE –∏ LINK)
            blocks = content.split('--------------------------------------------------')
            news_blocks = 0
            
            for block in blocks:
                if 'TITLE:' in block and 'LINK:' in block:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å, –∞ –Ω–µ –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    lines = block.strip().split('\n')
                    has_title = any('TITLE:' in line and len(line.replace('TITLE:', '').strip()) > 0 for line in lines)
                    has_link = any('LINK:' in line and len(line.replace('LINK:', '').strip()) > 0 for line in lines)
                    
                    if has_title and has_link:
                        news_blocks += 1
            
            logger.info(f"üìä –í —Ñ–∞–π–ª–µ –Ω–∞–π–¥–µ–Ω–æ –±–ª–æ–∫–æ–≤ —Å –Ω–æ–≤–æ—Å—Ç–µ–π: {news_blocks}")
            return news_blocks > 0
        
        else:
            # –ü—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç - –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—Ç—Ä–æ–∫ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º |
            lines = [line.strip() for line in content.split('\n') if line.strip()]
            news_lines = [line for line in lines if '|' in line]
            return len(news_lines) > 0

class AsyncYandexGPTMonitor:
    def __init__(self):
        self.api_url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        self.headers = {
            "Authorization": f"Api-Key {YANDEX_API_KEY}",
            "Content-Type": "application/json"
        }
        self.session = None
        self.token_usage = 0
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def yandex_gpt_call(self, prompt, max_tokens=2000):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ YandexGPT API"""
        try:
            data = {
                "modelUri": f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-lite",
                "completionOptions": {
                    "stream": False,
                    "temperature": 0.7,
                    "maxTokens": max_tokens
                },
                "messages": [
                    {
                        "role": "system",
                        "text": """–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä AI-–Ω–æ–≤–æ—Å—Ç–µ–π."""
                    },
                    {
                        "role": "user", 
                        "text": prompt
                    }
                ]
            }

            logger.info(f"üîç –ó–∞–ø—Ä–æ—Å –∫ YandexGPT ({len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤)")
            
            async with self.session.post(
                self.api_url, 
                headers=self.headers, 
                json=data, 
                timeout=aiohttp.ClientTimeout(total=90)
            ) as response:
                
                if response.status == 200:
                    result = await response.json()
                    if 'result' in result and 'alternatives' in result['result']:
                        content = result['result']['alternatives'][0]['message']['text']
                        
                        estimated_tokens = len(content) // 4 + len(prompt) // 4
                        self.token_usage += estimated_tokens
                        
                        cost = (estimated_tokens / 1000) * 0.60
                        logger.info(f"‚úÖ –û—Ç–≤–µ—Ç ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤, ~{estimated_tokens} —Ç–∫–Ω, {cost:.2f} —Ä—É–±)")
                        
                        return content
                    else:
                        logger.error(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞")
                        return None
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status}")
                    return None
                    
        except asyncio.TimeoutError:
            logger.error("‚ùå –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (90 —Å–µ–∫)")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return None

async def send_to_telegram_async(message, session):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram"""
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        payload = {
            "chat_id": TELEGRAM_CHANNEL_ID,
            "text": message,
            "parse_mode": "HTML",
            "disable_web_page_preview": True
        }
        
        async with session.post(url, json=payload, timeout=aiohttp.ClientTimeout(total=20)) as response:
            if response.status == 200:
                return True
            else:
                error_text = await response.text()
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ Telegram API: {response.status} - {error_text}")
                return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
        return False

async def process_news_for_telegram():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π - –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–∏"""
    news_manager = ExistingFilesNewsManager("results/github_*.txt")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–∞–º—É—é —Å—Ç–∞—Ä—É—é –Ω–µ–ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å
    news_data = news_manager.get_oldest_unsent_news()
    
    if not news_data:
        logger.info("‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É")
        return True
    
    news_line, news_hash, filepath = news_data
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –ª–∏ –º—ã —É–∂–µ —ç—Ç—É –Ω–æ–≤–æ—Å—Ç—å (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
    if news_hash in news_manager.sent_news:
        logger.warning(f"‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç—å —É–∂–µ –±—ã–ª–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞, –Ω–æ –≤—Å–µ –µ—â–µ –≤ —Ñ–∞–π–ª–µ: {news_line[:50]}...")
        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –∏ —É–¥–∞–ª—è–µ–º –∏–∑ —Ñ–∞–π–ª–∞
        news_manager.mark_news_sent_and_cleanup(news_hash, news_line, filepath)
        return True
    
    # –ü–∞—Ä—Å–∏–º –Ω–æ–≤–æ—Å—Ç—å (—Ñ–æ—Ä–º–∞—Ç: "–∑–∞–≥–æ–ª–æ–≤–æ–∫ | URL")
    if '|' in news_line:
        title, url = [part.strip() for part in news_line.split('|', 1)]
    else:
        title, url = news_line, ""

    logger.info(f"üì® –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ: {title}")
    logger.info(f"üîó URL: {url}")

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è YandexGPT —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    prompt = f"""
–ó–ê–î–ê–ß–ê: –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π –∏ —Å–æ–∑–¥–∞—Ç—å –∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ –Ω–æ–≤–æ—Å—Ç–∏: {url}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –§–û–†–ú–ê–¢–£ –ë–õ–û–ö–û–í:
1. –ó–∞–≥–æ–ª–æ–≤–æ–∫: –∫—Ä–∞—Ç–∫–∏–π, –ø—Ä–∏–≤–ª–µ–∫–∞—é—â–∏–π –≤–Ω–∏–º–∞–Ω–∏–µ
2. –¢–µ–∫—Å—Ç: 3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã
3. –í—ã–≤–æ–¥: –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø–æ–ª—å–∑–∞/–∑–Ω–∞—á–µ–Ω–∏–µ
4. –°—Å—ã–ª–∫–∞: –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π URL –±–µ–∑ –∞–Ω–∫–æ—Ä–∞
5. –•–µ—à—Ç–µ–≥–∏: 3-5 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–≥–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
- –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞: —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –±–æ–ª–∫–æ–≤ 1,2,3,4
- –ù–∏—á–µ–≥–æ –ª–∏—à–Ω–µ–≥–æ, –∫—Ä–æ–º–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ

–§–û–†–ú–ê–¢ –ë–õ–û–ö–û–í (–°–û–ë–õ–Æ–î–ê–ô –¢–û–ß–ù–û!):

üöÄ [–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ —Ä—É—Å—Å–∫–æ–º]

üìù [3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º]

üí° [1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–º –∑–Ω–∞—á–µ–Ω–∏–∏]

üîó {url}

üîñ #[—Ç–µ–º–∞—Ç–∏–∫–∞] #[—Ç–µ–º–∞—Ç–∏–∫–∞] #[—Ç–µ–º–∞—Ç–∏–∫–∞] #[–∫–æ–º–ø–∞–Ω–∏—è]

–ú–ï–ñ–î–£ –ö–ê–ñ–î–´–ú –ë–õ–û–ö–û–ú - –ü–£–°–¢–ê–Ø –°–¢–†–û–ö–ê!
"""
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ YandexGPT
    async with AsyncYandexGPTMonitor() as monitor:
        summarized_news = await monitor.yandex_gpt_call(prompt)
    
    if summarized_news:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram
        async with aiohttp.ClientSession() as session:
            success = await send_to_telegram_async(summarized_news, session)
            
            if success:
                # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –∏ —á–∏—Å—Ç–∏–º —Ñ–∞–π–ª—ã
                news_manager.mark_news_sent_and_cleanup(news_hash, news_line, filepath)
                logger.info("‚úÖ –ù–æ–≤–æ—Å—Ç—å —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –∏ —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã")
                return True
            else:
                logger.error("‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram")
                return False
    else:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–æ–≤–æ—Å—Ç—å —á–µ—Ä–µ–∑ YandexGPT")
        return False
        
async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    msk_time = datetime.now(timezone(timedelta(hours=3)))
    current_hour = msk_time.hour
    
    logger.info("=" * 60)
    logger.info("üöÄ AI News Monitor - –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ —Ñ–∞–π–ª–æ–≤")
    logger.info(f"‚è∞ –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è: {msk_time.strftime('%H:%M')} –ú–°–ö")
    logger.info("=" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    success = await process_news_for_telegram()
    
    if success:
        logger.info("üéâ –°–∫—Ä–∏–ø—Ç –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É")
    else:
        logger.warning("‚ö†Ô∏è –°–∫—Ä–∏–ø—Ç –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É —Å –æ—à–∏–±–∫–∞–º–∏")

if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    if not all([YANDEX_API_KEY, YANDEX_FOLDER_ID, TELEGRAM_BOT_TOKEN, TELEGRAM_CHANNEL_ID]):
        logger.error("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        exit(1)
    
    # –ó–∞–ø—É—Å–∫
    asyncio.run(main())
